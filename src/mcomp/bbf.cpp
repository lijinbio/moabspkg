#include <boost/exception/diagnostic_information.hpp>
#include <boost/exception_ptr.hpp>
#include <boost/algorithm/string/join.hpp>
#include <vector>

// Code generated by Stan version 2.6

#include <stan/model/model_header.hpp>
#include <stan/services/command.hpp>

#include "bbf.h"

std::vector <double> muall;
std::vector <double> ssall;

namespace betabinFit_model_namespace {

using std::istream;
using std::string;
using std::stringstream;
using std::vector;
using stan::io::dump;
using stan::math::lgamma;
using stan::model::prob_grad;
using namespace stan::math;
using namespace stan::math;
using namespace stan::prob;

typedef Eigen::Matrix<double,Eigen::Dynamic,1> vector_d;
typedef Eigen::Matrix<double,1,Eigen::Dynamic> row_vector_d;
typedef Eigen::Matrix<double,Eigen::Dynamic,Eigen::Dynamic> matrix_d;

class betabinFit_model : public prob_grad {
private:
    int Jx;
    vector<int> countx;
    vector<int> totalx;
public:
    betabinFit_model(stan::io::var_context& context__,
        std::ostream* pstream__ = 0)
        : prob_grad(0) {
        static const char* function__ = "betabinFit_model_namespace::betabinFit_model";
        (void) function__; // dummy call to supress warning
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<int> vals_i__;
        std::vector<double> vals_r__;
        context__.validate_dims("data initialization", "Jx", "int", context__.to_vec());
        Jx = int(0);
        vals_i__ = context__.vals_i("Jx");
        pos__ = 0;
        Jx = vals_i__[pos__++];
        context__.validate_dims("data initialization", "countx", "int", context__.to_vec(Jx));
        validate_non_negative_index("countx", "Jx", Jx);
        countx = std::vector<int>(Jx,int(0));
        vals_i__ = context__.vals_i("countx");
        pos__ = 0;
        size_t countx_limit_0__ = Jx;
        for (size_t i_0__ = 0; i_0__ < countx_limit_0__; ++i_0__) {
            countx[i_0__] = vals_i__[pos__++];
        }
        context__.validate_dims("data initialization", "totalx", "int", context__.to_vec(Jx));
        validate_non_negative_index("totalx", "Jx", Jx);
        totalx = std::vector<int>(Jx,int(0));
        vals_i__ = context__.vals_i("totalx");
        pos__ = 0;
        size_t totalx_limit_0__ = Jx;
        for (size_t i_0__ = 0; i_0__ < totalx_limit_0__; ++i_0__) {
            totalx[i_0__] = vals_i__[pos__++];
        }

        // validate data
        try { 
            check_greater_or_equal(function__,"Jx",Jx,0);
        } catch (const std::exception& e) { 
            throw std::domain_error(std::string("Invalid value of Jx: ") + std::string(e.what()));
        };

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning


        // initialized transformed params to avoid seg fault on val access

        // validate transformed data

        // set parameter ranges
        num_params_r__ = 0U;
        param_ranges_i__.clear();
        ++num_params_r__;
        ++num_params_r__;
        num_params_r__ += Jx;
    }

    ~betabinFit_model() { }


    void transform_inits(const stan::io::var_context& context__,
                         std::vector<int>& params_i__,
                         std::vector<double>& params_r__,
                         std::ostream* pstream__) const {
        stan::io::writer<double> writer__(params_r__,params_i__);
        size_t pos__;
        (void) pos__; // dummy call to supress warning
        std::vector<double> vals_r__;
        std::vector<int> vals_i__;


        if (!(context__.contains_r("mux")))
            throw std::runtime_error("variable mux missing");
        vals_r__ = context__.vals_r("mux");
        pos__ = 0U;
        context__.validate_dims("initialization", "mux", "double", context__.to_vec());
        double mux(0);
        mux = vals_r__[pos__++];
        try { writer__.scalar_lub_unconstrain(0,1,mux); } catch (const std::exception& e) {  throw std::runtime_error(std::string("Error transforming variable mux: ") + e.what()); }

        if (!(context__.contains_r("ssx")))
            throw std::runtime_error("variable ssx missing");
        vals_r__ = context__.vals_r("ssx");
        pos__ = 0U;
        context__.validate_dims("initialization", "ssx", "double", context__.to_vec());
        double ssx(0);
        ssx = vals_r__[pos__++];
        try { writer__.scalar_lb_unconstrain(0.001,ssx); } catch (const std::exception& e) {  throw std::runtime_error(std::string("Error transforming variable ssx: ") + e.what()); }

        if (!(context__.contains_r("probx")))
            throw std::runtime_error("variable probx missing");
        vals_r__ = context__.vals_r("probx");
        pos__ = 0U;
        context__.validate_dims("initialization", "probx", "double", context__.to_vec(Jx));
        std::vector<double> probx(Jx,double(0));
        for (int i0__ = 0U; i0__ < Jx; ++i0__)
            probx[i0__] = vals_r__[pos__++];
        for (int i0__ = 0U; i0__ < Jx; ++i0__)
            try { writer__.scalar_lub_unconstrain(0,1,probx[i0__]); } catch (const std::exception& e) {  throw std::runtime_error(std::string("Error transforming variable probx: ") + e.what()); }
        params_r__ = writer__.data_r();
        params_i__ = writer__.data_i();
    }

    void transform_inits(const stan::io::var_context& context,
                         Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                         std::ostream* pstream__) const {
      std::vector<double> params_r_vec;
      std::vector<int> params_i_vec;
      transform_inits(context, params_i_vec, params_r_vec, pstream__);
      params_r.resize(params_r_vec.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r(i) = params_r_vec[i];
    }


    template <bool propto__, bool jacobian__, typename T__>
    T__ log_prob(vector<T__>& params_r__,
                 vector<int>& params_i__,
                 std::ostream* pstream__ = 0) const {

        T__ DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning

        T__ lp__(0.0);
        stan::math::accumulator<T__> lp_accum__;

        // model parameters
        stan::io::reader<T__> in__(params_r__,params_i__);

        T__ mux;
        (void) mux;   // dummy to suppress unused var warning
        if (jacobian__)
            mux = in__.scalar_lub_constrain(0,1,lp__);
        else
            mux = in__.scalar_lub_constrain(0,1);

        T__ ssx;
        (void) ssx;   // dummy to suppress unused var warning
        if (jacobian__)
            ssx = in__.scalar_lb_constrain(0.001,lp__);
        else
            ssx = in__.scalar_lb_constrain(0.001);

        vector<T__> probx;
        size_t dim_probx_0__ = Jx;
        probx.reserve(dim_probx_0__);
        for (size_t k_0__ = 0; k_0__ < dim_probx_0__; ++k_0__) {
            if (jacobian__)
                probx.push_back(in__.scalar_lub_constrain(0,1,lp__));
            else
                probx.push_back(in__.scalar_lub_constrain(0,1));
        }


        // transformed parameters

        // initialized transformed params to avoid seg fault on val access


        // validate transformed parameters

        const char* function__ = "validate transformed params";
        (void) function__; // dummy to suppress unused var warning
        // model body
        lp_accum__.add(beta_log<propto__>(mux, 0.1, 0.1));
        lp_accum__.add(gamma_log<propto__>(ssx, 0.001, 0.001));
        lp_accum__.add(beta_log<propto__>(probx, (mux * ssx), ((1 - mux) * ssx)));
        lp_accum__.add(binomial_log<propto__>(countx, totalx, probx));

        lp_accum__.add(lp__);
        return lp_accum__.sum();

    } // log_prob()

    template <bool propto, bool jacobian, typename T_>
    T_ log_prob(Eigen::Matrix<T_,Eigen::Dynamic,1>& params_r,
               std::ostream* pstream = 0) const {
      std::vector<T_> vec_params_r;
      vec_params_r.reserve(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        vec_params_r.push_back(params_r(i));
      std::vector<int> vec_params_i;
      return log_prob<propto,jacobian,T_>(vec_params_r, vec_params_i, pstream);
    }


    void get_param_names(std::vector<std::string>& names__) const {
        names__.resize(0);
        names__.push_back("mux");
        names__.push_back("ssx");
        names__.push_back("probx");
    }


    void get_dims(std::vector<std::vector<size_t> >& dimss__) const {
        dimss__.resize(0);
        std::vector<size_t> dims__;
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dimss__.push_back(dims__);
        dims__.resize(0);
        dims__.push_back(Jx);
        dimss__.push_back(dims__);
    }

    template <typename RNG>
    void write_array(RNG& base_rng__,
                     std::vector<double>& params_r__,
                     std::vector<int>& params_i__,
                     std::vector<double>& vars__,
                     bool include_tparams__ = true,
                     bool include_gqs__ = true,
                     std::ostream* pstream__ = 0) const {
        vars__.resize(0);
        stan::io::reader<double> in__(params_r__,params_i__);
        static const char* function__ = "betabinFit_model_namespace::write_array";
        (void) function__; // dummy call to supress warning
        // read-transform, write parameters
        double mux = in__.scalar_lub_constrain(0,1);
        double ssx = in__.scalar_lb_constrain(0.001);
        vector<double> probx;
        size_t dim_probx_0__ = Jx;
        for (size_t k_0__ = 0; k_0__ < dim_probx_0__; ++k_0__) {
            probx.push_back(in__.scalar_lub_constrain(0,1));
        }
        vars__.push_back(mux);
        vars__.push_back(ssx);

		muall.push_back(mux);
		ssall.push_back(ssx);
		
        for (int k_0__ = 0; k_0__ < Jx; ++k_0__) {
            vars__.push_back(probx[k_0__]);
        }

        if (!include_tparams__) return;
        // declare and define transformed parameters
        double lp__ = 0.0;
        (void) lp__; // dummy call to supress warning
        stan::math::accumulator<double> lp_accum__;



        // validate transformed parameters

        // write transformed parameters

        if (!include_gqs__) return;
        // declare and define generated quantities

        double DUMMY_VAR__(std::numeric_limits<double>::quiet_NaN());
        (void) DUMMY_VAR__;  // suppress unused var warning


        // initialized transformed params to avoid seg fault on val access


        // validate generated quantities

        // write generated quantities
    }

    template <typename RNG>
    void write_array(RNG& base_rng,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                     Eigen::Matrix<double,Eigen::Dynamic,1>& vars,
                     bool include_tparams = true,
                     bool include_gqs = true,
                     std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<double> vars_vec;
      std::vector<int> params_i_vec;
      write_array(base_rng,params_r_vec,params_i_vec,vars_vec,include_tparams,include_gqs,pstream);
      vars.resize(vars_vec.size());
      for (int i = 0; i < vars.size(); ++i)
        vars(i) = vars_vec[i];
    }


    void write_csv_header(std::ostream& o__) const {
        stan::io::csv_writer writer__(o__);
        writer__.comma();
        o__ << "mux";
        writer__.comma();
        o__ << "ssx";
        for (int k_0__ = 1; k_0__ <= Jx; ++k_0__) {
            writer__.comma();
            o__ << "probx" << '.' << k_0__;
        }
        writer__.newline();
    }

    template <typename RNG>
    void write_csv(RNG& base_rng__,
                   std::vector<double>& params_r__,
                   std::vector<int>& params_i__,
                   std::ostream& o__,
                   std::ostream* pstream__ = 0) const {
        stan::io::reader<double> in__(params_r__,params_i__);
        stan::io::csv_writer writer__(o__);
        static const char* function__ = "betabinFit_model_namespace::write_csv";
        (void) function__; // dummy call to supress warning
        // read-transform, write parameters
        double mux = in__.scalar_lub_constrain(0,1);
        writer__.write(mux);
        double ssx = in__.scalar_lb_constrain(0.001);
        writer__.write(ssx);
        vector<double> probx;
        size_t dim_probx_0__ = Jx;
        for (size_t k_0__ = 0; k_0__ < dim_probx_0__; ++k_0__) {
            probx.push_back(in__.scalar_lub_constrain(0,1));
            writer__.write(probx[k_0__]);
        }

        // declare, define and validate transformed parameters
        double lp__ = 0.0;
        (void) lp__; // dummy call to supress warning
        stan::math::accumulator<double> lp_accum__;




        // write transformed parameters

        // declare and define generated quantities


        // validate generated quantities

        // write generated quantities
        writer__.newline();
    }

    template <typename RNG>
    void write_csv(RNG& base_rng,
                   Eigen::Matrix<double,Eigen::Dynamic,1>& params_r,
                   std::ostream& o,
                   std::ostream* pstream = 0) const {
      std::vector<double> params_r_vec(params_r.size());
      for (int i = 0; i < params_r.size(); ++i)
        params_r_vec[i] = params_r(i);
      std::vector<int> params_i_vec;  // dummy
      write_csv(base_rng, params_r_vec, params_i_vec, o, pstream);
    }

    static std::string model_name() {
        return "betabinFit_model";
    }


    void constrained_param_names(std::vector<std::string>& param_names__,
                                 bool include_tparams__ = true,
                                 bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        param_name_stream__.str(std::string());
        param_name_stream__ << "mux";
        param_names__.push_back(param_name_stream__.str());
        param_name_stream__.str(std::string());
        param_name_stream__ << "ssx";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= Jx; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "probx" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (!include_gqs__) return;
    }


    void unconstrained_param_names(std::vector<std::string>& param_names__,
                                   bool include_tparams__ = true,
                                   bool include_gqs__ = true) const {
        std::stringstream param_name_stream__;
        param_name_stream__.str(std::string());
        param_name_stream__ << "mux";
        param_names__.push_back(param_name_stream__.str());
        param_name_stream__.str(std::string());
        param_name_stream__ << "ssx";
        param_names__.push_back(param_name_stream__.str());
        for (int k_0__ = 1; k_0__ <= Jx; ++k_0__) {
            param_name_stream__.str(std::string());
            param_name_stream__ << "probx" << '.' << k_0__;
            param_names__.push_back(param_name_stream__.str());
        }

        if (!include_gqs__ && !include_tparams__) return;

        if (!include_gqs__) return;
    }

}; // model

} // namespace

typedef betabinFit_model_namespace::betabinFit_model stan_model;


// // It has been defined in `types.h`, so remove it from here
// class BiKey {
//   public:
//     int  n1;
//     int  k1;
// 
//     BiKey(long N1, int K1)
//       : n1(N1), k1(K1) {}
// 
//     bool operator<(const BiKey &right) const
//     {
//         if ( n1 == right.n1 ) {
//         	return k1 < right.k1;
//         }
//         else {
//             return n1 < right.n1;
//         }
//     }
// };
// 


int beta_binomial_fit_wrapper(int ac, const char* av[], std::istringstream & ifs, BiKey & bk) {
  try {


    stan::services::command<stan_model>(ac, av, ifs);
    //std::cout << muSet << std::endl;
    //std::cout << ssSet << std::endl;
    //std::cout << setCount << std::endl;

	std::nth_element(muall.begin(), muall.begin() + muall.size() / 2, muall.end());
	double mumedian = muall[muall.size() / 2];
	std::nth_element(ssall.begin(), ssall.begin() + ssall.size() / 2, ssall.end());
	double ssmedian = ssall[ssall.size() / 2];
	
	double alpha = mumedian * ssmedian;
	double beta  = (1 - mumedian) * ssmedian;
   
    double kdouble = alpha - 1; //alpha = k + 1
    double ndouble = beta + kdouble - 1;//beta = n - k + 1
    
    int k = int (kdouble + 0.5);
    int n = int (ndouble + 0.5); 
    if(k>n){n=k;}

//    std::cout << "n=" << n << std::endl;
//    std::cout << "k=" << k << std::endl;
//    std::cout << "alpha=" << alpha << std::endl;
//    std::cout << "beta =" << beta  << std::endl;
//
//    std::cout << "muSet =" << muSet  << std::endl;
//    std::cout << "ssSet =" << ssSet  << std::endl;
//    std::cout << "count =" << setCount  << std::endl;

    bk.n1 = n;
    bk.k1 = k;

		// Bug fix By Jin Li @ 20190809
		// Clear these global vectors, otherwise, they will grow continously
		muall.clear();
		ssall.clear();

    return 0;
  } catch (const std::exception& e) {
    std::cerr << std::endl << "Exception: " << e.what() << std::endl;
    std::cerr << "Diagnostic information: " << std::endl << boost::diagnostic_information(e) << std::endl;
    return -1;
  }
}

int BetaBinomialFit(std::vector<int> & ni, std::vector<int> & ki, BiKey & bk){
	 //./program sample data file=betabinFit.data.R random seed=123

	std::stringstream kstream;
	std::copy(ki.begin(), ki.end(), std::ostream_iterator<int>(kstream, ","));
	std::string ks=kstream.str();
	ks.erase(ks.length()-1);

	std::stringstream nstream;
	std::copy(ni.begin(), ni.end(), std::ostream_iterator<int>(nstream, ","));
	std::string ns=nstream.str();
	ns.erase(ns.length()-1);

	std::stringstream ss;
	ss << "Jx <- " << ni.size() << std::endl;
	ss << "countx <- c( " << ks << " )" << std::endl;
	ss << "totalx <- c( " << ns << " )" << std::endl;

	//std::cout << ss.str() << std::endl;

	std::istringstream ifs( ss.str() );

	const char* arr[] = {"PROGRAM", "sample", "data", "file=filename","random", "seed=123"};


	beta_binomial_fit_wrapper(6, arr, ifs, bk);
	return 0;
}

// int main(int arc, const char* argv[]){
// 
// 	std::cout << arc << std::endl;
// 	std::vector<int> n;
// 	std::vector<int> k;
// 
// 	for(int i = 1; i < arc; i++){
// 		if(i<= arc /2){
// 			n.push_back( atoi (argv[i]));
// 		} else {
// 			k.push_back( atoi (argv[i]));
// 		}
// 	}
// 	std::copy(n.begin(), n.end(), std::ostream_iterator<int>(std::cout, "~"));
// 	std::cout << "====================" << std::endl;
// 	std::copy(k.begin(), k.end(), std::ostream_iterator<int>(std::cout, "~"));
// 	std::cout << "====================" << std::endl;
// 	BiKey bk(-1,-1);
// 	BetaBinomialFit(n, k, bk);
// 	std::cout << bk.n1 << "," << bk.k1 << std::endl;
// 	return 0;
// }

